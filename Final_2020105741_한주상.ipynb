# BeautifulSoup, Urlopen 그리고 Selenium 기법 생성하기
from bs4 import BeautifulSoup
from urllib.request import urlopen
from urllib.parse import quote_plus
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import time
from urllib.request import urlretrieve
import os

# 출처 인터넷 데이터 출처를 모아서 데이터를 압축하여서 Jupyter notebook에 다 모아놓기 - (1)
url_1 = "https://livecorona.co.kr"
driver_1 = webdriver.Chrome()
driver_1.get(url_1)
html_1 = driver_1.page_source
soup_1 = BeautifulSoup(html_1)
table_1 = soup_1.select('.card-body.text-center')
for element_1 in table_1:
    print("국내 확진자: {}".format(element_1.select_one('.count-text.mb-3').text))
driver_1.close()

# 코로나바이러스감영증-19(COVID-19) 홈페이지 출처 인용하기

def data_chart(url_2):
    html_2 = urlopen(url_2).read()
    soup_2 = BeautifulSoup(html_2, 'html.parser')
    nums_1 = soup_2.find_all('span', class_ = 'num')
    nums_2 = soup_2.find_all('span', class_ = 'before')
    nums_3 = soup_2.find_all(class_ = 'num_rnum')
    nums_4 = soup_2.find_all(class_ = 'num_percentage')
    nums_5 = soup_2.find('span', class_ = 'data1')
    nums_6 = soup_2.find('span', class_ = 'data2')
    # 환자현황 분석하기
    print("일일 확진환자: " + nums_5.text + "명")
    print("일일 완치자: " + nums_6.text + "명")
    print("누적 확진환자: " + nums_1[0].text + "명" + nums_2[0].text)
    print()
    print("완치: " + nums_1[1].text + "명" + nums_2[1].text)
    print()
    print("치료 중: " + nums_1[2].text + "명" + nums_2[2].text)
    print()
    print("사망: " + nums_1[3].text + "명" + nums_2[3].text)
    print()
    # 검사현황 분석하기
    print('검사현황')
    print()
    print("누적 검사 수: " + nums_1[4].text + "명")
    print()
    print("누적 검사 완료 수: " + nums_1[5].text + "명")
    print()
    print("누적 확진률: " + nums_1[6].text)
    print()
    print("검사중: " + nums_3[0].text + "명")
    print(nums_4[0].text)
    print()
    print("결과양성(확진):" + nums_3[1].text + "명")
    print(nums_4[1].text)
    print()
    print("결과음성:" + nums_3[2].text + "명")
    print(nums_4[2].text)
    print()
    # 시도별 확진자 현황 분석하기
    print("서울 확진자: " + nums_1[7].text + "명" + nums_2[3].text)
    print()
    print("부산 확진자: " + nums_1[8].text + "명" + nums_2[4].text)
    print()
    print("대구 확진자: " + nums_1[9].text + "명" + nums_2[5].text)
    print()
    print("인천 확진자: " + nums_1[10].text + "명" + nums_2[6].text)
    print()
    print("광주 확진자: " + nums_1[11].text + "명" + nums_2[7].text)
    print()
    print("대전 확진자: " + nums_1[12].text + "명" + nums_2[8].text)
    print()
    print("울산 확진자: " + nums_1[13].text + "명" + nums_2[9].text)
    print()
    print("세종 확진자: " + nums_1[14].text + "명" + nums_2[10].text)
    print()
    print("경기 확진자: " + nums_1[15].text + "명" + nums_2[11].text)
    print()
    print("강원 확진자: " + nums_1[16].text + "명" + nums_2[12].text)
    print()
    print("충북 확진자: " + nums_1[17].text + "명" + nums_2[13].text)
    print()
    print("충남 확진자: " + nums_1[18].text + "명" + nums_2[14].text)
    print()
    print("전북 확진자: " + nums_1[19].text + "명" + nums_2[15].text)
    print()
    print("전남 확진자: " + nums_1[20].text + "명" + nums_2[16].text)
    print()
    print("경북 확진자: " + nums_1[21].text + "명" + nums_2[17].text)
    print()
    print("경남 확진자: " + nums_1[22].text + "명" + nums_2[18].text)
    print()
    print("제주 확진자: " + nums_1[23].text + "명" + nums_2[19].text)
    print()
    print("검역 확진자: " + nums_1[24].text + "명" + nums_2[20].text)
    print()
if __name__ == '__main__':
    url_2 = "http://ncov.mohw.go.kr/"
    data_chart(url_2)
    
    print("접속중")
def download_images_1(Keyword_1):

    driver_2 = webdriver.Chrome()
    driver_2.implicitly_wait(30)
    url_3 = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=image&query='+ quote_plus(Keyword_1) 
    driver_2.get(url_3)
    body_1 = driver_2.find_element_by_css_selector('body')
    for i in range(1):
        body_1.send_keys(Keys.PAGE_DOWN)
        time.sleep(1)
    imgs_1 = driver_2.find_elements_by_css_selector('img._img')
    result_1 = []
    for img_1 in imgs_1:
        if 'http' in img_1.get_attribute('src'):
            result_1.append(img_1.get_attribute('src'))
    print(result_1)
    print("수집 완료")
    driver_2.close()
    if not os.path.isdir('./{}'.format(Keyword_1)):
        os.mkdir('./{}'.format(Keyword_1))
    for index_1, link_1 in enumerate(result_1):
        start_1 = link_1.rfind('.')
        end_1 = link_1.rfind('&')
        filetype_1 = link_1[start_1:end_1]
        urlretrieve(link_1, './{}/{}{}{}'.format(Keyword_1, Keyword_1, index_1, filetype_1))
    print("다운로드 완료")
if __name__ == '__main__':
    question_1 = input("대한민국코로나확진자증가추이를 조사하는 것이 맞나요?: ")
    if question_1 == "Yes":
        Keyword_1 = "대한민국코로나확진자증가추이"
        download_images_1(Keyword_1)
    else:
        print("error")
        
print("접속중")
def download_images_2(Keyword_2):

    driver_3 = webdriver.Chrome()
    driver_3.implicitly_wait(30)
    url_4 = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=image&query='+ quote_plus(Keyword_2) 
    driver_3.get(url_4)
    body_2 = driver_3.find_element_by_css_selector('body')
    for i in range(1):
        body_2.send_keys(Keys.PAGE_DOWN)
        time.sleep(1)
    imgs_2 = driver_3.find_elements_by_css_selector('img._img')
    result_2 = []
    for img_2 in imgs_2:
        if 'http' in img_2.get_attribute('src'):
            result_2.append(img_2.get_attribute('src'))
    print(result_2)
    print("수집 완료")
    driver_3.close()
    
    if not os.path.isdir('./{}'.format(Keyword_2)):
        os.mkdir('./{}'.format(Keyword_2))

    for index_2, link_2 in enumerate(result_2):
        start_2 = link_2.rfind('.')
        end_2 = link_2.rfind('&')
        filetype_2 = link_2[start_2:end_2]
        urlretrieve(link_2, './{}/{}{}{}'.format(Keyword_2, Keyword_2, index_2, filetype_2))
    print("다운로드 완료")

if __name__ == '__main__':
    question_2 = input("코로나전국확진자비율를 조사하는 것이 맞나요?: ")
    if question_2 == "Yes":
        Keyword_2 = "코로나전국확진자비율"
        download_images_2(Keyword_2)
    else:
        print("error")
        
        
print("접속중")
def download_images_2(Keyword_2):

    driver_3 = webdriver.Chrome()
    driver_3.implicitly_wait(30)
    url_4 = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=image&query='+ quote_plus(Keyword_2) 
    driver_3.get(url_4)
    body_2 = driver_3.find_element_by_css_selector('body')
    for i in range(1):
        body_2.send_keys(Keys.PAGE_DOWN)
        time.sleep(1)
    imgs_2 = driver_3.find_elements_by_css_selector('img._img')
    result_2 = []
    for img_2 in imgs_2:
        if 'http' in img_2.get_attribute('src'):
            result_2.append(img_2.get_attribute('src'))
    print(result_2)
    print("수집 완료")
    driver_3.close()
    
    if not os.path.isdir('./{}'.format(Keyword_2)):
        os.mkdir('./{}'.format(Keyword_2))

    for index_2, link_2 in enumerate(result_2):
        start_2 = link_2.rfind('.')
        end_2 = link_2.rfind('&')
        filetype_2 = link_2[start_2:end_2]
        urlretrieve(link_2, './{}/{}{}{}'.format(Keyword_2, Keyword_2, index_2, filetype_2))
    print("다운로드 완료")

if __name__ == '__main__':
    question_2 = input("코로나전국확진자비율를 조사하는 것이 맞나요?: ")
    if question_2 == "Yes":
        Keyword_2 = "코로나전국확진자비율"
        download_images_2(Keyword_2)
    else:
        print("error")
        
        
 print("접속중")
def download_images_4(Keyword_4):

    driver_5 = webdriver.Chrome()
    driver_5.implicitly_wait(30)
    url_6 = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=image&query='+ quote_plus(Keyword_4) 
    driver_5.get(url_6)
    body_4 = driver_5.find_element_by_css_selector('body')
    for i in range(1):
        body_4.send_keys(Keys.PAGE_DOWN)
        time.sleep(1)
    imgs_4 = driver_5.find_elements_by_css_selector('img._img')
    result_4 = []
    for img_4 in imgs_4:
        if 'http' in img_4.get_attribute('src'):
            result_4.append(img_4.get_attribute('src'))
    print(result_4)
    print("수집 완료")
    driver_5.close()
    
    if not os.path.isdir('./{}'.format(Keyword_4)):
        os.mkdir('./{}'.format(Keyword_4))

    for index_4, link_4 in enumerate(result_4):
        start_4 = link_4.rfind('.')
        end_4 = link_4.rfind('&')
        filetype_4 = link_4[start_4:end_4]
        urlretrieve(link_4, './{}/{}{}{}'.format(Keyword_4, Keyword_4, index_4, filetype_4))
    print("다운로드 완료")

if __name__ == '__main__':
    question_4 = input("코로나국내현황지도를 조사하는 것이 맞나요?: ")
    if question_4 == "Yes":
        Keyword_4 = "코로나국내현황지도"
        download_images_4(Keyword_4)
    else:
        print("error")
        
print("접속중")
def download_images_1(Keyword_5):

    driver_6 = webdriver.Chrome()
    driver_6.implicitly_wait(30)
    url_7 = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=image&query='+ quote_plus(Keyword_5) 
    driver_6.get(url_7)
    body_5 = driver_6.find_element_by_css_selector('body')
    for i in range(1):
        body_5.send_keys(Keys.PAGE_DOWN)
        time.sleep(1)
    imgs_5 = driver_6.find_elements_by_css_selector('img._img')
    result_5 = []
    for img_5 in imgs_5:
        if 'http' in img_5.get_attribute('src'):
            result_5.append(img_5.get_attribute('src'))
    print(result_5)
    print("수집 완료")
    driver_6.close()
    if not os.path.isdir('./{}'.format(Keyword_5)):
        os.mkdir('./{}'.format(Keyword_5))

    for index_5, link_5 in enumerate(result_5):
        start_5 = link_5.rfind('.')
        end_5 = link_5.rfind('&')
        filetype_5 = link_5[start_5:end_5]
        urlretrieve(link_5, './{}/{}{}{}'.format(Keyword_5, Keyword_5, index_5, filetype_5))
    print("다운로드 완료")

if __name__ == '__main__':
    question_5 = input("코로나시도별확진자현황지도를 조사하는 것이 맞나요?: ")
    if question_5 == "Yes":
        Keyword_5 = "코로나시도별확진자현황지도"
        download_images_1(Keyword_5)
    else:
        print("error")
